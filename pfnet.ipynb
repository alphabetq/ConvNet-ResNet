{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "764fe135-c09e-9769-5794-500867154d93"
   },
   "source": [
    "Starter EDA and ConvNet implementation using Keras. \n",
    "\n",
    "Inspiration for this notebook comes from this [Keras blog post](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) and the [VGG ConvNet paper](https://arxiv.org/pdf/1409.1556.pdf). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d458c15-e131-f3c4-f756-843d6454bb37"
   },
   "outputs": [],
   "source": [
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "import pyttsx3 \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from os.path import realpath, normpath\n",
    "print(cv2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# lol = []\n",
    "# path1 = '../test/' \n",
    "\n",
    "# listing = os.listdir(path1)    \n",
    "# for file in listing:\n",
    "#     if 'Comp' in file: \n",
    "#         lol = path1 + file\n",
    "#         img=mpimg.imread(path1 + file)\n",
    "#         imgplot = plt.imshow(img)\n",
    "#         plt.show()\n",
    "# print(len(lol))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "663d335e-1b84-a8cb-19ee-8f04839cf4e5"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "ROWS = 64\n",
    "COLS = 64\n",
    "CHANNELS = 3\n",
    "\n",
    "train_images = [] # use this for full dataset\n",
    "train_passed =   []\n",
    "train_failed =   []\n",
    "test_images =  []\n",
    "test_passed =   []\n",
    "test_failed =   []\n",
    "\n",
    "TRAIN_PASSED_DIR = 'C:/train-folder/passed/'\n",
    "TRAIN_FAILED_DIR = 'C:/train-folder/failed/'\n",
    "TEST_PASSED_DIR = 'C:/test-folder/passed/'\n",
    "TEST_FAILED_DIR = 'C:/test-folder/failed/'\n",
    "\n",
    "if not os.path.exists(TEST_PASSED_DIR):\n",
    "    os.makedirs(TEST_PASSED_DIR)\n",
    "if not os.path.exists(TEST_FAILED_DIR):\n",
    "    os.makedirs(TEST_FAILED_DIR)\n",
    "\n",
    "train_passed =   [TRAIN_PASSED_DIR+i for i in os.listdir(TRAIN_PASSED_DIR) if '.db' not in i]\n",
    "train_failed =   [TRAIN_FAILED_DIR+i for i in os.listdir(TRAIN_FAILED_DIR) if '.db' not in i]\n",
    "train_images = train_passed + train_failed # use this for full dataset\n",
    "\n",
    "test_passed =   [TEST_PASSED_DIR+i for i in os.listdir(TEST_PASSED_DIR) if '.db' not in i]\n",
    "test_failed =   [TEST_FAILED_DIR+i for i in os.listdir(TEST_FAILED_DIR) if '.db' not in i]\n",
    "test_images = test_passed + test_failed # use this for full dataset\n",
    "\n",
    "# test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "# slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\n",
    "# train_images = train_passed[:1000] + train_failed[:1000]\n",
    "# test_images =  test_images[:25]\n",
    "\n",
    "print('Train images: ' + str(len(train_images)) + ', passed: ' + str(len(train_passed)) + ', failed: ' + str(len(train_failed)))\n",
    "print('Test images: ' + str(len(test_images)) + ', passed: ' + str(len(test_passed)) + ', failed: ' + str(len(test_failed)))\n",
    "random.shuffle(train_images)\n",
    "# random.shuffle(test_images)\n",
    "\n",
    "\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(str(file_path), cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image.T\n",
    "        if i == (len(images)-1): print('Processed {} of {}'.format(i+1, count))\n",
    "        else: print('Processed {} of {}'.format(i+1, count), end='\\r')\n",
    "    return data\n",
    "\n",
    "train = prep_data(train_images)\n",
    "test = prep_data(test_images)\n",
    "\n",
    "print(\"Train shape: {}\".format(train.shape))\n",
    "print(\"Test shape: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c0f2fbf6-8d78-7d42-6579-5486a36c1e60"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in train_images:\n",
    "    if 'passed' in i:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "\n",
    "sns.countplot(labels)\n",
    "plt.title('Passed:(1) and failed:(0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0b7c79ae-6543-2ed8-e3f5-af4f5beb9cf7"
   },
   "outputs": [],
   "source": [
    "def show_passed_and_failed(idx):\n",
    "    passed = read_image(train_passed[idx])\n",
    "    failed = read_image(train_failed[idx])\n",
    "    pair = np.concatenate((passed, failed), axis=1)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair)\n",
    "    plt.show()\n",
    "    \n",
    "for idx in range(0,5):\n",
    "    show_passed_and_failed(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7d3c6eb7-c370-9752-67c8-c780bab14abe"
   },
   "outputs": [],
   "source": [
    "passed_avg = np.array([passed[0].T for i, passed in enumerate(train) if labels[i]==1]).mean(axis=0)\n",
    "plt.imshow(passed_avg)\n",
    "plt.title('Your Average Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a5a93063-de92-18ce-b48f-68a193e90002"
   },
   "outputs": [],
   "source": [
    "failed_avg = np.array([failed[0].T for i, failed in enumerate(train) if labels[i]==0]).mean(axis=0)\n",
    "plt.imshow(failed_avg)\n",
    "plt.title('Your Average Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c477612-41d3-3112-5176-3c4ad9633080"
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "\n",
    "def passedorfailed():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, 3, padding='same', input_shape=(3, ROWS, COLS), activation='relu'))\n",
    "    model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "    model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    \n",
    "    model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    \n",
    "    model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
    "#     model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "#     model.add(Conv2D(512, 3, padding='same', activation='relu'))\n",
    "#     model.add(Conv2D(512, 3, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "#     model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
    "#     model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
    "#     model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = passedorfailed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca613169-4b41-e9d5-27c7-6629f8e035c8"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "## Callback for loss logging per epoch\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=2, mode='auto')        \n",
    "        \n",
    "def run_pf():\n",
    "    \n",
    "    history = LossHistory()\n",
    "    model.fit(train, labels, batch_size=batch_size, epochs=epochs,\n",
    "              validation_split=0.25, verbose=1, shuffle=True, callbacks=[history, early_stopping])\n",
    "    predictions = model.predict(test, verbose=2)\n",
    "    return predictions, history\n",
    "\n",
    "predictions, history = run_pf()\n",
    "\n",
    "engine = pyttsx3.init('sapi5', True)\n",
    "engine.say('Model training completed.')\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6266d01c-9d4c-a1dc-8cb9-ce7b3107b536"
   },
   "outputs": [],
   "source": [
    "loss = history.losses\n",
    "val_loss = history.val_losses\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG-16 Loss Trend')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,epochs)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c665d01b-a5a7-2f7e-e5d4-09e108920e40"
   },
   "outputs": [],
   "source": [
    "true_p = 0\n",
    "false_p = 0\n",
    "true_n = 0\n",
    "false_n = 0\n",
    "\n",
    "unidentified = 0\n",
    "file_moved_passed = 0\n",
    "file_exist_passed = 0\n",
    "file_moved_failed = 0\n",
    "file_exist_failed = 0\n",
    "\n",
    "# fig=plt.figure(figsize=(15,20*len(predictions)/5))\n",
    "for i in range(len(predictions)):\n",
    "#     fig.add_subplot(len(predictions), 5, i+1)\n",
    "    if test_images[i] in test_passed:\n",
    "        if predictions[i, 0] >= 0.5:\n",
    "            true_p += 1\n",
    "#             plt.title('{:.2%} '.format(predictions[i][0]) + 'passed')\n",
    "        else: \n",
    "            false_n += 1\n",
    "            plt.title('{:.2%} '.format(1-predictions[i][0]) + 'failed')\n",
    "            plt.imshow(test[i].T)\n",
    "            plt.show()\n",
    "            rep = test_passed[i].replace(\"passed\", \"failed\", 1)\n",
    "            rep = rep.replace(\"Measurement\", \"Open\", 1)\n",
    "            \n",
    "            print('ORI: ' + test_passed[i])\n",
    "            if os.path.exists(test_passed[i]):\n",
    "                if os.path.exists(rep):\n",
    "                    os.remove(test_passed[i])\n",
    "                    print('NEW: File already exists.')\n",
    "                    file_exist_failed += 1\n",
    "                else:\n",
    "                    os.rename(test_passed[i], rep)\n",
    "                    print('NEW: ' + rep)\n",
    "                    file_moved_passed += 1\n",
    "            else: print('NEW: File not exist in \\'passed\\' folder')\n",
    "            \n",
    "    elif test_images[i] in test_failed:\n",
    "        ii = (len(test_failed) - (len(test_images) - len(test_passed)) + 1)\n",
    "        if predictions[i, 0] >= 0.5:\n",
    "            false_p += 1\n",
    "            plt.title('{:.2%} '.format(predictions[i][0]) + 'passed')\n",
    "            plt.imshow(test[i].T)\n",
    "            plt.show()\n",
    "            rep = test_failed[ii].replace(\"failed\", \"passed\", 1)\n",
    "            rep = rep.replace(\"Open\", \"Measurement\", 1)\n",
    "            \n",
    "            print('ORI: ' + test_failed[ii])\n",
    "            if os.path.exists(test_failed[ii]):\n",
    "                if os.path.exists(rep):\n",
    "                    os.remove(test_failed[ii])\n",
    "                    print('NEW: File already exists.')\n",
    "                    file_exist_passed += 1\n",
    "                else:\n",
    "                    os.rename(test_failed[ii], rep)\n",
    "                    print('NEW: ' + rep)\n",
    "                    file_moved_failed += 1\n",
    "            else: print('NEW: File not exist in \\'failed\\' folder')\n",
    "        else: \n",
    "            true_n += 1\n",
    "#             plt.title('{:.2%} '.format(1-predictions[i][0]) + 'failed')\n",
    "    else: unidentified += 1\n",
    "    print('Processed {} of {}'.format(i+1, len(test_images)), end = '\\r')\n",
    "#     plt.imshow(test[i].T)\n",
    "#     plt.show()\n",
    "        \n",
    "\n",
    "print('')\n",
    "print('File unidentified: ' + str(unidentified))\n",
    "print('File moved from \\'passed\\' folder: ' + str(file_moved_passed))\n",
    "print('File exists in \\'failed\\' folder: ' + str(file_exist_failed))\n",
    "print('File moved from \\'failed\\' folder: ' + str(file_moved_failed))\n",
    "print('File exists in \\'passed\\' folder: ' + str(file_exist_passed))\n",
    "\n",
    "engine = pyttsx3.init('sapi5', True)\n",
    "engine.say('Image processing completed. Here are the results.')\n",
    "# engine.say(str(unidentified) + ' files unidentified.')\n",
    "# engine.say(str(file_moved_passed) + ' files moved from \\'passed\\' folder.')\n",
    "# engine.say(str(file_exist_failed) + ' files exists in \\'failed\\' folder.')\n",
    "# engine.say(str(file_moved_failed) + ' files moved from \\'failed\\' folder.')\n",
    "# engine.say(str(file_exist_passed) + ' files exists in \\'passed\\' folder.')\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "print('Total: ' + str(len(predictions)))\n",
    "print('Passed: ' + str(len(test_passed)))\n",
    "print('Failed: ' + str(len(test_failed)))\n",
    "\n",
    "s = \"\"\"\n",
    "</style>\n",
    "<table>\n",
    "<tr>\n",
    "<td></td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "<th colspan=\"2\" style=\"text-align:center\">Actual</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td></td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "<td>Positive</td>\n",
    "<td>Negative</td>\n",
    "</tr>\n",
    "<tr>\n",
    "\n",
    "<th rowspan=\"2\">Predicted </td>\n",
    "<td>Positive </td>\n",
    "<td></td>\n",
    "<td><i style=\"color:green\">True Positive:</i><i> (\"\"\" + str(true_p) + \"\"\")</i> </td>\n",
    "<td><i style=\"color:red\">False Positive:</i><i> (\"\"\" + str(false_p) + \"\"\")</i></td>\n",
    "</tr>\n",
    "<tr>\n",
    "\n",
    "<td>Negative: </td>\n",
    "<td></td>\n",
    "<td><i style=\"color:red\">False Negative:</i><i> (\"\"\" + str(false_n) + \"\"\")</i></td>\n",
    "<td><i style=\"color:green\">True Negative:</i><i> (\"\"\" + str(true_n) + \"\"\")</i> </td>\n",
    "</tr>\n",
    "</table>\"\"\"\n",
    "\n",
    "h = HTML(s)\n",
    "display(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 205,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
